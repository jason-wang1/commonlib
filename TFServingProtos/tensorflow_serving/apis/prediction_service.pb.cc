// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow_serving/apis/prediction_service.proto

#include "tensorflow_serving/apis/prediction_service.pb.h"

#include <algorithm>

#include <google/protobuf/io/coded_stream.h>
#include <google/protobuf/extension_set.h>
#include <google/protobuf/wire_format_lite.h>
#include <google/protobuf/descriptor.h>
#include <google/protobuf/generated_message_reflection.h>
#include <google/protobuf/reflection_ops.h>
#include <google/protobuf/wire_format.h>
// @@protoc_insertion_point(includes)
#include <google/protobuf/port_def.inc>
namespace tensorflow {
namespace serving {
}  // namespace serving
}  // namespace tensorflow
static constexpr ::PROTOBUF_NAMESPACE_ID::Metadata* file_level_metadata_tensorflow_5fserving_2fapis_2fprediction_5fservice_2eproto = nullptr;
static constexpr ::PROTOBUF_NAMESPACE_ID::EnumDescriptor const** file_level_enum_descriptors_tensorflow_5fserving_2fapis_2fprediction_5fservice_2eproto = nullptr;
static constexpr ::PROTOBUF_NAMESPACE_ID::ServiceDescriptor const** file_level_service_descriptors_tensorflow_5fserving_2fapis_2fprediction_5fservice_2eproto = nullptr;
const ::PROTOBUF_NAMESPACE_ID::uint32 TableStruct_tensorflow_5fserving_2fapis_2fprediction_5fservice_2eproto::offsets[1] = {};
static constexpr ::PROTOBUF_NAMESPACE_ID::internal::MigrationSchema* schemas = nullptr;
static constexpr ::PROTOBUF_NAMESPACE_ID::Message* const* file_default_instances = nullptr;

const char descriptor_table_protodef_tensorflow_5fserving_2fapis_2fprediction_5fservice_2eproto[] PROTOBUF_SECTION_VARIABLE(protodesc_cold) =
  "\n0tensorflow_serving/apis/prediction_ser"
  "vice.proto\022\022tensorflow.serving\032%tensorfl"
  "ow_serving/apis/predict.proto2g\n\021Predict"
  "ionService\022R\n\007Predict\022\".tensorflow.servi"
  "ng.PredictRequest\032#.tensorflow.serving.P"
  "redictResponseB\003\370\001\001b\006proto3"
  ;
static const ::PROTOBUF_NAMESPACE_ID::internal::DescriptorTable*const descriptor_table_tensorflow_5fserving_2fapis_2fprediction_5fservice_2eproto_deps[1] = {
  &::descriptor_table_tensorflow_5fserving_2fapis_2fpredict_2eproto,
};
static ::PROTOBUF_NAMESPACE_ID::internal::SCCInfoBase*const descriptor_table_tensorflow_5fserving_2fapis_2fprediction_5fservice_2eproto_sccs[1] = {
};
static ::PROTOBUF_NAMESPACE_ID::internal::once_flag descriptor_table_tensorflow_5fserving_2fapis_2fprediction_5fservice_2eproto_once;
const ::PROTOBUF_NAMESPACE_ID::internal::DescriptorTable descriptor_table_tensorflow_5fserving_2fapis_2fprediction_5fservice_2eproto = {
  false, false, descriptor_table_protodef_tensorflow_5fserving_2fapis_2fprediction_5fservice_2eproto, "tensorflow_serving/apis/prediction_service.proto", 227,
  &descriptor_table_tensorflow_5fserving_2fapis_2fprediction_5fservice_2eproto_once, descriptor_table_tensorflow_5fserving_2fapis_2fprediction_5fservice_2eproto_sccs, descriptor_table_tensorflow_5fserving_2fapis_2fprediction_5fservice_2eproto_deps, 0, 1,
  schemas, file_default_instances, TableStruct_tensorflow_5fserving_2fapis_2fprediction_5fservice_2eproto::offsets,
  file_level_metadata_tensorflow_5fserving_2fapis_2fprediction_5fservice_2eproto, 0, file_level_enum_descriptors_tensorflow_5fserving_2fapis_2fprediction_5fservice_2eproto, file_level_service_descriptors_tensorflow_5fserving_2fapis_2fprediction_5fservice_2eproto,
};

// Force running AddDescriptors() at dynamic initialization time.
static bool dynamic_init_dummy_tensorflow_5fserving_2fapis_2fprediction_5fservice_2eproto = (static_cast<void>(::PROTOBUF_NAMESPACE_ID::internal::AddDescriptors(&descriptor_table_tensorflow_5fserving_2fapis_2fprediction_5fservice_2eproto)), true);
namespace tensorflow {
namespace serving {

// @@protoc_insertion_point(namespace_scope)
}  // namespace serving
}  // namespace tensorflow
PROTOBUF_NAMESPACE_OPEN
PROTOBUF_NAMESPACE_CLOSE

// @@protoc_insertion_point(global_scope)
#include <google/protobuf/port_undef.inc>
